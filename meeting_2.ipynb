{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate linear data\n",
        "torch.manual_seed(0)\n",
        "x = torch.linspace(0, 10, 100).reshape(-1, 1)  # Input (features)\n",
        "y = 2 * x + 3 + torch.randn(100, 1) * 0.5     # Output (target) with some noise\n",
        "\n",
        "\n",
        "class LinearNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LinearNN, self).__init__()\n",
        "        self.linear = nn.Linear(1, 1)  # One input and one output\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "# Initialize the model, loss function, and optimizer\n",
        "model = LinearNN()\n",
        "criterion = nn.MSELoss()  # Mean Squared Error Loss\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)  # Stochastic Gradient Descent\n",
        "\n",
        "# Train the model\n",
        "epochs = 1000\n",
        "for epoch in range(epochs):\n",
        "    # Forward pass\n",
        "    predictions = model(x)\n",
        "    loss = criterion(predictions, y)\n",
        "\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Print loss every 100 epochs\n",
        "    if (epoch + 1) % 100 == 0:\n",
        "        print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Visualize the results\n",
        "with torch.no_grad():\n",
        "    predicted = model(x)\n",
        "\n",
        "plt.scatter(x, y, label='Original Data')\n",
        "plt.plot(x, predicted, color='red', label='Fitted Line')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 604
        },
        "id": "ofzpD1SnFx7q",
        "outputId": "7d035988-f24c-482b-9ce7-f46b95fa197b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [100/1000], Loss: 0.8920\n",
            "Epoch [200/1000], Loss: 0.4951\n",
            "Epoch [300/1000], Loss: 0.3484\n",
            "Epoch [400/1000], Loss: 0.2942\n",
            "Epoch [500/1000], Loss: 0.2741\n",
            "Epoch [600/1000], Loss: 0.2667\n",
            "Epoch [700/1000], Loss: 0.2640\n",
            "Epoch [800/1000], Loss: 0.2630\n",
            "Epoch [900/1000], Loss: 0.2626\n",
            "Epoch [1000/1000], Loss: 0.2625\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "single neuron with two layers classification\n"
      ],
      "metadata": {
        "id": "KS9mlZnyJah-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load the dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# One-hot encoding for classification\n",
        "y_encoded = to_categorical(y)\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the neural network\n",
        "model = Sequential()\n",
        "model.add(Dense(5, input_dim=X.shape[1], activation='relu'))  # Hidden layer with 5 neurons\n",
        "model.add(Dense(3, activation='softmax'))  # Output layer (3 classes for Iris species)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=100, verbose=0)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "y_true = np.argmax(y_test, axis=-1)\n",
        "\n",
        "# Accuracy score\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "print(f\"Classification Accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXpGKK0BIH9A",
        "outputId": "795a8d70-db64-4256-b003-024cde9a150c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
            "Classification Accuracy: 0.6333333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "single neuron with two layers regession"
      ],
      "metadata": {
        "id": "i9tTfF6oJhi9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Sample data (inputs and outputs)\n",
        "X = np.array([[1], [2], [3], [4], [5]])  # Input features\n",
        "y = np.array([1, 2, 3, 4, 5])            # Output labels\n",
        "\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "\n",
        "# Add a hidden layer with 5 neurons and ReLU activation\n",
        "model.add(Dense(5, input_dim=1, activation='relu'))\n",
        "\n",
        "# Output layer with 1 neuron (for regression)\n",
        "model.add(Dense(1))\n",
        "\n",
        "# Compile the model with Mean Squared Error loss function and Adam optimizer\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y, epochs=100, verbose=0)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(X)\n",
        "print(predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VNxI6FjJhGG",
        "outputId": "f8a62ca4-8f50-4092-9e19-a624ef39bed5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "[[0.8834352]\n",
            " [1.517029 ]\n",
            " [2.1306424]\n",
            " [2.7363908]\n",
            " [3.342139 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "single neuron with one layer linear data\n"
      ],
      "metadata": {
        "id": "xprmgex7NDKu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class Neuron:\n",
        "    def __init__(self, input_size, learning_rate=0.01):\n",
        "        # Initialize weights and bias\n",
        "        self.weights = np.random.randn(input_size)\n",
        "        self.bias = np.random.randn()\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "    def activation(self, x):\n",
        "        # Linear activation function\n",
        "        return x\n",
        "\n",
        "    def activation_derivative(self, x):\n",
        "        # Derivative of linear activation function (constant 1)\n",
        "        return 1\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # Calculate weighted sum plus bias\n",
        "        self.inputs = inputs\n",
        "        self.z = np.dot(inputs, self.weights) + self.bias\n",
        "        # Apply linear activation function\n",
        "        self.output = self.activation(self.z)\n",
        "        return self.output\n",
        "\n",
        "    def backward(self, error):\n",
        "        # Calculate gradient\n",
        "        d_output = error * self.activation_derivative(self.output)\n",
        "        d_weights = np.dot(self.inputs.T, d_output)\n",
        "        d_bias = np.sum(d_output)\n",
        "\n",
        "        # Update weights and bias\n",
        "        self.weights -= self.learning_rate * d_weights\n",
        "        self.bias -= self.learning_rate * d_bias\n",
        "\n",
        "    def train(self, inputs, target):\n",
        "        # Forward pass\n",
        "        output = self.forward(inputs)\n",
        "        # Calculate error\n",
        "        error = target - output\n",
        "        # Backward pass\n",
        "        self.backward(error)\n",
        "        return error\n",
        "\n",
        "# Example usage\n",
        "neuron = Neuron(3)\n",
        "inputs = np.array([[0.5, -0.2, 0.1]])\n",
        "target = np.array([1])\n",
        "\n",
        "# Training loop\n",
        "for _ in range(1000):\n",
        "    error = neuron.train(inputs, target)\n",
        "\n",
        "print(\"Final output:\", neuron.forward(inputs))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFtJcgreNCl2",
        "outputId": "34590ead-33f8-4f8e-85a2-6d961f903e82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final output: [-709899.81530455]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "single neuron on non linear data\n"
      ],
      "metadata": {
        "id": "5Q1F054bNUQU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class Neuron:\n",
        "    def __init__(self, input_size, learning_rate=0.01):\n",
        "        # Initialize weights and bias\n",
        "        self.weights = np.random.randn(input_size)\n",
        "        self.bias = np.random.randn()\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "    def activation(self, x):\n",
        "        # Sigmoid activation function for non-linear data\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def activation_derivative(self, x):\n",
        "        # Derivative of sigmoid\n",
        "        return x * (1 - x)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # Calculate weighted sum plus bias\n",
        "        self.inputs = inputs\n",
        "        self.z = np.dot(inputs, self.weights) + self.bias\n",
        "        # Apply activation function\n",
        "        self.output = self.activation(self.z)\n",
        "        return self.output\n",
        "\n",
        "    def backward(self, error):\n",
        "        # Calculate gradient\n",
        "        d_output = error * self.activation_derivative(self.output)\n",
        "        d_weights = np.dot(self.inputs.T, d_output)\n",
        "        d_bias = np.sum(d_output)\n",
        "\n",
        "        # Update weights and bias\n",
        "        self.weights -= self.learning_rate * d_weights\n",
        "        self.bias -= self.learning_rate * d_bias\n",
        "\n",
        "    def train(self, inputs, target):\n",
        "        # Forward pass\n",
        "        output = self.forward(inputs)\n",
        "        # Calculate error\n",
        "        error = target - output\n",
        "        # Backward pass\n",
        "        self.backward(error)\n",
        "        return error\n",
        "\n",
        "# Example usage\n",
        "neuron = Neuron(3)\n",
        "inputs = np.array([[0.5, -0.2, 0.1]])\n",
        "target = np.array([1])\n",
        "\n",
        "# Training loop\n",
        "for _ in range(1000):\n",
        "    error = neuron.train(inputs, target)\n",
        "\n",
        "print(\"Final output:\", neuron.forward(inputs))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjxfTiDmOgnm",
        "outputId": "e7bdaa95-9fad-4acc-c820-2f9a01057771"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final output: [0.20543921]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate Linear Data\n",
        "x_linear = np.linspace(-10, 10, 100)\n",
        "y_linear = 2 * x_linear + 5  # Linear relationship\n",
        "\n",
        "# Generate Non-Linear Data\n",
        "y_non_linear = x_linear**2 + 2 * x_linear + 5  # Quadratic relationship\n",
        "\n",
        "# Training Loop for Linear Model (Sigmoid Activation)\n",
        "neuron = Neuron(1)  # 1 input feature\n",
        "error_linear = []\n",
        "error_non_linear = []\n",
        "\n",
        "# Training on Linear Data\n",
        "for x_value, y_value in zip(x_linear, y_linear):\n",
        "    inputs = np.array([[x_value]])\n",
        "    target = np.array([y_value])\n",
        "    error_linear.append(neuron.train(inputs, target))\n",
        "\n",
        "# Training on Non-Linear Data\n",
        "for x_value, y_value in zip(x_linear, y_non_linear):\n",
        "    inputs = np.array([[x_value]])\n",
        "    target = np.array([y_value])\n",
        "    error_non_linear.append(neuron.train(inputs, target))\n",
        "\n",
        "# Plotting Error Curves\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(error_linear, label=\"Error on Linear Data\", color='blue')\n",
        "plt.plot(error_non_linear, label=\"Error on Non-Linear Data\", color='red')\n",
        "plt.legend()\n",
        "plt.xlabel('Training Steps')\n",
        "plt.ylabel('Error')\n",
        "plt.title('Training Error Comparison (Linear vs Non-Linear Data)')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "jXWeiR9ATUQ8",
        "outputId": "acc6c983-a70e-4b63-9cf4-a9a7e81ef1e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nnfs\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBamb3O4T4VT",
        "outputId": "1a9eeaf0-a069-4e4b-dd99-a3a8868813ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nnfs\n",
            "  Downloading nnfs-0.5.1-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from nnfs) (1.26.4)\n",
            "Downloading nnfs-0.5.1-py3-none-any.whl (9.1 kB)\n",
            "Installing collected packages: nnfs\n",
            "Successfully installed nnfs-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "my code accuarcay,precison,recall,f1-score"
      ],
      "metadata": {
        "id": "fDPDj6LAJwG3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import nnfs\n",
        "from nnfs.datasets import spiral_data\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "\n",
        "nnfs.init()\n",
        "\n",
        "# Define classes\n",
        "class Layer_Dense:\n",
        "    def __init__(self, n_inputs, n_neurons):\n",
        "        self.weights = 0.01 * np.random.randn(n_inputs, n_neurons)\n",
        "        self.biases = np.zeros((1, n_neurons))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        self.inputs = inputs\n",
        "        self.output = np.dot(inputs, self.weights) + self.biases\n",
        "\n",
        "    def backward(self, dvalues):\n",
        "        self.dweights = np.dot(self.inputs.T, dvalues)\n",
        "        self.dbiases = np.sum(dvalues, axis=0, keepdims=True)\n",
        "        self.dinputs = np.dot(dvalues, self.weights.T)\n",
        "\n",
        "class Activation_ReLU:\n",
        "    def forward(self, inputs):\n",
        "        self.inputs = inputs\n",
        "        self.output = np.maximum(0, inputs)\n",
        "\n",
        "    def backward(self, dvalues):\n",
        "        self.dinputs = dvalues.copy()\n",
        "        self.dinputs[self.inputs <= 0] = 0\n",
        "\n",
        "class Activation_Softmax:\n",
        "    def forward(self, inputs):\n",
        "        exp_values = np.exp(inputs - np.max(inputs, axis=1, keepdims=True))\n",
        "        self.output = exp_values / np.sum(exp_values, axis=1, keepdims=True)\n",
        "\n",
        "class Loss:\n",
        "    def calculate(self, output, y):\n",
        "        sample_losses = self.forward(output, y)\n",
        "        return np.mean(sample_losses)\n",
        "\n",
        "class Loss_CategoricalCrossentropy(Loss):\n",
        "    def forward(self, y_pred, y_true):\n",
        "        samples = len(y_pred)\n",
        "        y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
        "\n",
        "        if len(y_true.shape) == 1:\n",
        "            correct_confidences = y_pred_clipped[range(samples), y_true]\n",
        "        elif len(y_true.shape) == 2:\n",
        "            correct_confidences = np.sum(y_pred_clipped * y_true, axis=1)\n",
        "\n",
        "        negative_log_likelihoods = -np.log(correct_confidences)\n",
        "        return negative_log_likelihoods\n",
        "\n",
        "    def backward(self, dvalues, y_true):\n",
        "        samples = len(dvalues)\n",
        "        labels = len(dvalues[0])\n",
        "\n",
        "        if len(y_true.shape) == 1:\n",
        "            y_true = np.eye(labels)[y_true]\n",
        "\n",
        "        self.dinputs = -y_true / dvalues\n",
        "        self.dinputs = self.dinputs / samples\n",
        "\n",
        "class Activation_Softmax_Loss_CategoricalCrossentropy:\n",
        "    def __init__(self):\n",
        "        self.activation = Activation_Softmax()\n",
        "        self.loss = Loss_CategoricalCrossentropy()\n",
        "\n",
        "    def forward(self, inputs, y_true):\n",
        "        self.activation.forward(inputs)\n",
        "        self.output = self.activation.output\n",
        "        return self.loss.calculate(self.output, y_true)\n",
        "\n",
        "    def backward(self, dvalues, y_true):\n",
        "        samples = len(dvalues)\n",
        "        if len(y_true.shape) == 2:\n",
        "            y_true = np.argmax(y_true, axis=1)\n",
        "        self.dinputs = dvalues.copy()\n",
        "        self.dinputs[range(samples), y_true] -= 1\n",
        "        self.dinputs = self.dinputs / samples\n",
        "\n",
        "# Optimizer\n",
        "class Optimizer_Adam:\n",
        "    def __init__(self, learning_rate=0.001, decay=0., epsilon=1e-7, beta_1=0.9, beta_2=0.999):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.current_learning_rate = learning_rate\n",
        "        self.decay = decay\n",
        "        self.iterations = 0\n",
        "        self.epsilon = epsilon\n",
        "        self.beta_1 = beta_1\n",
        "        self.beta_2 = beta_2\n",
        "\n",
        "    def pre_update_params(self):\n",
        "        if self.decay:\n",
        "            self.current_learning_rate = self.learning_rate * (1. / (1. + self.decay * self.iterations))\n",
        "\n",
        "    def update_params(self, layer):\n",
        "        if not hasattr(layer, 'weight_cache'):\n",
        "            layer.weight_momentums = np.zeros_like(layer.weights)\n",
        "            layer.weight_cache = np.zeros_like(layer.weights)\n",
        "            layer.bias_momentums = np.zeros_like(layer.biases)\n",
        "            layer.bias_cache = np.zeros_like(layer.biases)\n",
        "\n",
        "        layer.weight_momentums = self.beta_1 * layer.weight_momentums + (1 - self.beta_1) * layer.dweights\n",
        "        layer.bias_momentums = self.beta_1 * layer.bias_momentums + (1 - self.beta_1) * layer.dbiases\n",
        "\n",
        "        weight_momentums_corrected = layer.weight_momentums / (1 - self.beta_1 ** (self.iterations + 1))\n",
        "        bias_momentums_corrected = layer.bias_momentums / (1 - self.beta_1 ** (self.iterations + 1))\n",
        "\n",
        "        layer.weight_cache = self.beta_2 * layer.weight_cache + (1 - self.beta_2) * layer.dweights**2\n",
        "        layer.bias_cache = self.beta_2 * layer.bias_cache + (1 - self.beta_2) * layer.dbiases**2\n",
        "\n",
        "        weight_cache_corrected = layer.weight_cache / (1 - self.beta_2 ** (self.iterations + 1))\n",
        "        bias_cache_corrected = layer.bias_cache / (1 - self.beta_2 ** (self.iterations + 1))\n",
        "\n",
        "        layer.weights += -self.current_learning_rate * weight_momentums_corrected / (np.sqrt(weight_cache_corrected) + self.epsilon)\n",
        "        layer.biases += -self.current_learning_rate * bias_momentums_corrected / (np.sqrt(bias_cache_corrected) + self.epsilon)\n",
        "\n",
        "    def post_update_params(self):\n",
        "        self.iterations += 1\n",
        "\n",
        "# Create dataset\n",
        "X, y = spiral_data(samples=100, classes=3)\n",
        "\n",
        "# Create Dense layers\n",
        "dense1 = Layer_Dense(2, 64)\n",
        "activation1 = Activation_ReLU()\n",
        "dense2 = Layer_Dense(64, 3)\n",
        "loss_activation = Activation_Softmax_Loss_CategoricalCrossentropy()\n",
        "optimizer = Optimizer_Adam(learning_rate=0.02, decay=1e-5)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(10001):\n",
        "    dense1.forward(X)\n",
        "    activation1.forward(dense1.output)\n",
        "    dense2.forward(activation1.output)\n",
        "    loss = loss_activation.forward(dense2.output, y)\n",
        "\n",
        "    # Predictions\n",
        "    predictions = np.argmax(loss_activation.output, axis=1)\n",
        "\n",
        "    # Compute metrics\n",
        "    acc = accuracy_score(y, predictions)\n",
        "    f1 = f1_score(y, predictions, average='weighted')\n",
        "    precision = precision_score(y, predictions, average='weighted', zero_division=1)\n",
        "    recall = recall_score(y, predictions, average='weighted', zero_division=1)\n",
        "\n",
        "    if not epoch % 100:\n",
        "        print(f'Epoch: {epoch}, Acc: {acc:.3f}, Loss: {loss:.3f}, F1: {f1:.3f}, Precision: {precision:.3f}, Recall: {recall:.3f}, LR: {optimizer.current_learning_rate}')\n",
        "\n",
        "    # Backpropagation\n",
        "    loss_activation.backward(loss_activation.output, y)\n",
        "    dense2.backward(loss_activation.dinputs)\n",
        "    activation1.backward(dense2.dinputs)\n",
        "    dense1.backward(activation1.dinputs)\n",
        "\n",
        "    # Update parameters\n",
        "    optimizer.pre_update_params()\n",
        "    optimizer.update_params(dense1)\n",
        "    optimizer.update_params(dense2)\n",
        "    optimizer.post_update_params()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzlrCsDmJpy-",
        "outputId": "76bf5874-a052-4d7f-e8e1-8822001bb453"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Acc: 0.360, Loss: 1.099, F1: 0.284, Precision: 0.353, Recall: 0.360, LR: 0.02\n",
            "Epoch: 100, Acc: 0.673, Loss: 0.769, F1: 0.669, Precision: 0.669, Recall: 0.673, LR: 0.01998021958261321\n",
            "Epoch: 200, Acc: 0.813, Loss: 0.552, F1: 0.812, Precision: 0.812, Recall: 0.813, LR: 0.019960279044701046\n",
            "Epoch: 300, Acc: 0.840, Loss: 0.445, F1: 0.840, Precision: 0.843, Recall: 0.840, LR: 0.019940378268975763\n",
            "Epoch: 400, Acc: 0.863, Loss: 0.380, F1: 0.863, Precision: 0.865, Recall: 0.863, LR: 0.01992051713662487\n",
            "Epoch: 500, Acc: 0.873, Loss: 0.336, F1: 0.874, Precision: 0.874, Recall: 0.873, LR: 0.01990069552930875\n",
            "Epoch: 600, Acc: 0.890, Loss: 0.308, F1: 0.890, Precision: 0.891, Recall: 0.890, LR: 0.019880913329158343\n",
            "Epoch: 700, Acc: 0.890, Loss: 0.287, F1: 0.890, Precision: 0.891, Recall: 0.890, LR: 0.019861170418772778\n",
            "Epoch: 800, Acc: 0.907, Loss: 0.269, F1: 0.906, Precision: 0.906, Recall: 0.907, LR: 0.019841466681217078\n",
            "Epoch: 900, Acc: 0.910, Loss: 0.250, F1: 0.910, Precision: 0.910, Recall: 0.910, LR: 0.01982180200001982\n",
            "Epoch: 1000, Acc: 0.913, Loss: 0.238, F1: 0.913, Precision: 0.913, Recall: 0.913, LR: 0.019802176259170884\n",
            "Epoch: 1100, Acc: 0.910, Loss: 0.230, F1: 0.910, Precision: 0.910, Recall: 0.910, LR: 0.01978258934311912\n",
            "Epoch: 1200, Acc: 0.913, Loss: 0.219, F1: 0.913, Precision: 0.913, Recall: 0.913, LR: 0.01976304113677013\n",
            "Epoch: 1300, Acc: 0.920, Loss: 0.210, F1: 0.920, Precision: 0.920, Recall: 0.920, LR: 0.019743531525483964\n",
            "Epoch: 1400, Acc: 0.910, Loss: 0.202, F1: 0.910, Precision: 0.911, Recall: 0.910, LR: 0.01972406039507293\n",
            "Epoch: 1500, Acc: 0.917, Loss: 0.192, F1: 0.917, Precision: 0.917, Recall: 0.917, LR: 0.019704627631799327\n",
            "Epoch: 1600, Acc: 0.920, Loss: 0.187, F1: 0.920, Precision: 0.921, Recall: 0.920, LR: 0.019685233122373254\n",
            "Epoch: 1700, Acc: 0.937, Loss: 0.184, F1: 0.936, Precision: 0.937, Recall: 0.937, LR: 0.019665876753950384\n",
            "Epoch: 1800, Acc: 0.930, Loss: 0.172, F1: 0.930, Precision: 0.930, Recall: 0.930, LR: 0.01964655841412981\n",
            "Epoch: 1900, Acc: 0.933, Loss: 0.167, F1: 0.933, Precision: 0.933, Recall: 0.933, LR: 0.019627277990951823\n",
            "Epoch: 2000, Acc: 0.933, Loss: 0.162, F1: 0.933, Precision: 0.933, Recall: 0.933, LR: 0.019608035372895814\n",
            "Epoch: 2100, Acc: 0.933, Loss: 0.158, F1: 0.933, Precision: 0.933, Recall: 0.933, LR: 0.01958883044887805\n",
            "Epoch: 2200, Acc: 0.933, Loss: 0.154, F1: 0.933, Precision: 0.933, Recall: 0.933, LR: 0.019569663108249594\n",
            "Epoch: 2300, Acc: 0.943, Loss: 0.151, F1: 0.943, Precision: 0.943, Recall: 0.943, LR: 0.01955053324079414\n",
            "Epoch: 2400, Acc: 0.953, Loss: 0.150, F1: 0.953, Precision: 0.954, Recall: 0.953, LR: 0.019531440736725945\n",
            "Epoch: 2500, Acc: 0.940, Loss: 0.145, F1: 0.940, Precision: 0.940, Recall: 0.940, LR: 0.019512385486687673\n",
            "Epoch: 2600, Acc: 0.947, Loss: 0.142, F1: 0.946, Precision: 0.946, Recall: 0.947, LR: 0.019493367381748363\n",
            "Epoch: 2700, Acc: 0.950, Loss: 0.140, F1: 0.950, Precision: 0.950, Recall: 0.950, LR: 0.019474386313401298\n",
            "Epoch: 2800, Acc: 0.947, Loss: 0.137, F1: 0.946, Precision: 0.946, Recall: 0.947, LR: 0.019455442173562\n",
            "Epoch: 2900, Acc: 0.950, Loss: 0.135, F1: 0.950, Precision: 0.950, Recall: 0.950, LR: 0.019436534854566128\n",
            "Epoch: 3000, Acc: 0.947, Loss: 0.132, F1: 0.946, Precision: 0.946, Recall: 0.947, LR: 0.01941766424916747\n",
            "Epoch: 3100, Acc: 0.940, Loss: 0.138, F1: 0.940, Precision: 0.943, Recall: 0.940, LR: 0.019398830250535893\n",
            "Epoch: 3200, Acc: 0.953, Loss: 0.129, F1: 0.953, Precision: 0.953, Recall: 0.953, LR: 0.019380032752255354\n",
            "Epoch: 3300, Acc: 0.947, Loss: 0.127, F1: 0.946, Precision: 0.946, Recall: 0.947, LR: 0.01936127164832186\n",
            "Epoch: 3400, Acc: 0.947, Loss: 0.125, F1: 0.946, Precision: 0.946, Recall: 0.947, LR: 0.01934254683314152\n",
            "Epoch: 3500, Acc: 0.947, Loss: 0.124, F1: 0.946, Precision: 0.946, Recall: 0.947, LR: 0.019323858201528515\n",
            "Epoch: 3600, Acc: 0.950, Loss: 0.123, F1: 0.950, Precision: 0.950, Recall: 0.950, LR: 0.019305205648703173\n",
            "Epoch: 3700, Acc: 0.947, Loss: 0.122, F1: 0.946, Precision: 0.946, Recall: 0.947, LR: 0.01928658907028997\n",
            "Epoch: 3800, Acc: 0.947, Loss: 0.120, F1: 0.946, Precision: 0.946, Recall: 0.947, LR: 0.01926800836231563\n",
            "Epoch: 3900, Acc: 0.950, Loss: 0.119, F1: 0.950, Precision: 0.950, Recall: 0.950, LR: 0.019249463421207133\n",
            "Epoch: 4000, Acc: 0.960, Loss: 0.120, F1: 0.960, Precision: 0.960, Recall: 0.960, LR: 0.019230954143789846\n",
            "Epoch: 4100, Acc: 0.953, Loss: 0.118, F1: 0.953, Precision: 0.954, Recall: 0.953, LR: 0.019212480427285565\n",
            "Epoch: 4200, Acc: 0.953, Loss: 0.118, F1: 0.953, Precision: 0.954, Recall: 0.953, LR: 0.019194042169310647\n",
            "Epoch: 4300, Acc: 0.963, Loss: 0.119, F1: 0.963, Precision: 0.964, Recall: 0.963, LR: 0.019175639267874092\n",
            "Epoch: 4400, Acc: 0.950, Loss: 0.118, F1: 0.950, Precision: 0.951, Recall: 0.950, LR: 0.019157271621375684\n",
            "Epoch: 4500, Acc: 0.953, Loss: 0.115, F1: 0.953, Precision: 0.953, Recall: 0.953, LR: 0.0191389391286041\n",
            "Epoch: 4600, Acc: 0.963, Loss: 0.114, F1: 0.963, Precision: 0.963, Recall: 0.963, LR: 0.019120641688735073\n",
            "Epoch: 4700, Acc: 0.950, Loss: 0.115, F1: 0.950, Precision: 0.952, Recall: 0.950, LR: 0.019102379201329525\n",
            "Epoch: 4800, Acc: 0.953, Loss: 0.112, F1: 0.953, Precision: 0.954, Recall: 0.953, LR: 0.01908415156633174\n",
            "Epoch: 4900, Acc: 0.957, Loss: 0.111, F1: 0.956, Precision: 0.957, Recall: 0.957, LR: 0.01906595868406753\n",
            "Epoch: 5000, Acc: 0.947, Loss: 0.110, F1: 0.946, Precision: 0.947, Recall: 0.947, LR: 0.01904780045524243\n",
            "Epoch: 5100, Acc: 0.953, Loss: 0.107, F1: 0.953, Precision: 0.954, Recall: 0.953, LR: 0.019029676780939874\n",
            "Epoch: 5200, Acc: 0.957, Loss: 0.106, F1: 0.956, Precision: 0.957, Recall: 0.957, LR: 0.019011587562619416\n",
            "Epoch: 5300, Acc: 0.957, Loss: 0.105, F1: 0.956, Precision: 0.957, Recall: 0.957, LR: 0.01899353270211493\n",
            "Epoch: 5400, Acc: 0.953, Loss: 0.104, F1: 0.953, Precision: 0.954, Recall: 0.953, LR: 0.018975512101632844\n",
            "Epoch: 5500, Acc: 0.950, Loss: 0.105, F1: 0.950, Precision: 0.951, Recall: 0.950, LR: 0.018957525663750367\n",
            "Epoch: 5600, Acc: 0.957, Loss: 0.102, F1: 0.956, Precision: 0.957, Recall: 0.957, LR: 0.018939573291413745\n",
            "Epoch: 5700, Acc: 0.960, Loss: 0.111, F1: 0.960, Precision: 0.961, Recall: 0.960, LR: 0.018921654887936498\n",
            "Epoch: 5800, Acc: 0.963, Loss: 0.100, F1: 0.963, Precision: 0.963, Recall: 0.963, LR: 0.018903770356997706\n",
            "Epoch: 5900, Acc: 0.957, Loss: 0.100, F1: 0.956, Precision: 0.957, Recall: 0.957, LR: 0.018885919602640248\n",
            "Epoch: 6000, Acc: 0.960, Loss: 0.098, F1: 0.960, Precision: 0.960, Recall: 0.960, LR: 0.018868102529269144\n",
            "Epoch: 6100, Acc: 0.960, Loss: 0.098, F1: 0.960, Precision: 0.961, Recall: 0.960, LR: 0.018850319041649778\n",
            "Epoch: 6200, Acc: 0.967, Loss: 0.097, F1: 0.967, Precision: 0.967, Recall: 0.967, LR: 0.018832569044906263\n",
            "Epoch: 6300, Acc: 0.960, Loss: 0.096, F1: 0.960, Precision: 0.960, Recall: 0.960, LR: 0.018814852444519702\n",
            "Epoch: 6400, Acc: 0.963, Loss: 0.096, F1: 0.963, Precision: 0.963, Recall: 0.963, LR: 0.018797169146326564\n",
            "Epoch: 6500, Acc: 0.957, Loss: 0.095, F1: 0.956, Precision: 0.957, Recall: 0.957, LR: 0.01877951905651696\n",
            "Epoch: 6600, Acc: 0.967, Loss: 0.095, F1: 0.967, Precision: 0.967, Recall: 0.967, LR: 0.018761902081633034\n",
            "Epoch: 6700, Acc: 0.967, Loss: 0.094, F1: 0.967, Precision: 0.967, Recall: 0.967, LR: 0.018744318128567278\n",
            "Epoch: 6800, Acc: 0.967, Loss: 0.093, F1: 0.967, Precision: 0.967, Recall: 0.967, LR: 0.018726767104560903\n",
            "Epoch: 6900, Acc: 0.967, Loss: 0.093, F1: 0.967, Precision: 0.967, Recall: 0.967, LR: 0.018709248917202218\n",
            "Epoch: 7000, Acc: 0.967, Loss: 0.092, F1: 0.967, Precision: 0.967, Recall: 0.967, LR: 0.018691763474424996\n",
            "Epoch: 7100, Acc: 0.967, Loss: 0.092, F1: 0.967, Precision: 0.967, Recall: 0.967, LR: 0.018674310684506857\n",
            "Epoch: 7200, Acc: 0.967, Loss: 0.091, F1: 0.967, Precision: 0.967, Recall: 0.967, LR: 0.01865689045606769\n",
            "Epoch: 7300, Acc: 0.963, Loss: 0.090, F1: 0.963, Precision: 0.963, Recall: 0.963, LR: 0.01863950269806802\n",
            "Epoch: 7400, Acc: 0.967, Loss: 0.090, F1: 0.967, Precision: 0.967, Recall: 0.967, LR: 0.018622147319807447\n",
            "Epoch: 7500, Acc: 0.960, Loss: 0.089, F1: 0.960, Precision: 0.960, Recall: 0.960, LR: 0.018604824230923075\n",
            "Epoch: 7600, Acc: 0.967, Loss: 0.089, F1: 0.967, Precision: 0.967, Recall: 0.967, LR: 0.01858753334138793\n",
            "Epoch: 7700, Acc: 0.960, Loss: 0.091, F1: 0.960, Precision: 0.961, Recall: 0.960, LR: 0.018570274561509396\n",
            "Epoch: 7800, Acc: 0.960, Loss: 0.088, F1: 0.960, Precision: 0.960, Recall: 0.960, LR: 0.018553047801927663\n",
            "Epoch: 7900, Acc: 0.970, Loss: 0.089, F1: 0.970, Precision: 0.970, Recall: 0.970, LR: 0.018535852973614212\n",
            "Epoch: 8000, Acc: 0.967, Loss: 0.088, F1: 0.967, Precision: 0.967, Recall: 0.967, LR: 0.01851868998787026\n",
            "Epoch: 8100, Acc: 0.963, Loss: 0.087, F1: 0.963, Precision: 0.963, Recall: 0.963, LR: 0.018501558756325222\n",
            "Epoch: 8200, Acc: 0.967, Loss: 0.088, F1: 0.967, Precision: 0.967, Recall: 0.967, LR: 0.01848445919093522\n",
            "Epoch: 8300, Acc: 0.963, Loss: 0.086, F1: 0.963, Precision: 0.963, Recall: 0.963, LR: 0.018467391203981567\n",
            "Epoch: 8400, Acc: 0.960, Loss: 0.085, F1: 0.960, Precision: 0.960, Recall: 0.960, LR: 0.018450354708069265\n",
            "Epoch: 8500, Acc: 0.960, Loss: 0.085, F1: 0.960, Precision: 0.960, Recall: 0.960, LR: 0.018433349616125496\n",
            "Epoch: 8600, Acc: 0.963, Loss: 0.085, F1: 0.963, Precision: 0.963, Recall: 0.963, LR: 0.018416375841398172\n",
            "Epoch: 8700, Acc: 0.960, Loss: 0.084, F1: 0.960, Precision: 0.960, Recall: 0.960, LR: 0.01839943329745444\n",
            "Epoch: 8800, Acc: 0.967, Loss: 0.084, F1: 0.967, Precision: 0.967, Recall: 0.967, LR: 0.01838252189817921\n",
            "Epoch: 8900, Acc: 0.963, Loss: 0.084, F1: 0.963, Precision: 0.963, Recall: 0.963, LR: 0.018365641557773718\n",
            "Epoch: 9000, Acc: 0.960, Loss: 0.083, F1: 0.960, Precision: 0.960, Recall: 0.960, LR: 0.018348792190754044\n",
            "Epoch: 9100, Acc: 0.963, Loss: 0.083, F1: 0.963, Precision: 0.963, Recall: 0.963, LR: 0.0183319737119497\n",
            "Epoch: 9200, Acc: 0.973, Loss: 0.085, F1: 0.973, Precision: 0.973, Recall: 0.973, LR: 0.018315186036502167\n",
            "Epoch: 9300, Acc: 0.960, Loss: 0.086, F1: 0.960, Precision: 0.962, Recall: 0.960, LR: 0.018298429079863496\n",
            "Epoch: 9400, Acc: 0.967, Loss: 0.083, F1: 0.967, Precision: 0.967, Recall: 0.967, LR: 0.018281702757794862\n",
            "Epoch: 9500, Acc: 0.967, Loss: 0.082, F1: 0.967, Precision: 0.967, Recall: 0.967, LR: 0.018265006986365174\n",
            "Epoch: 9600, Acc: 0.970, Loss: 0.090, F1: 0.970, Precision: 0.971, Recall: 0.970, LR: 0.018248341681949654\n",
            "Epoch: 9700, Acc: 0.963, Loss: 0.081, F1: 0.963, Precision: 0.963, Recall: 0.963, LR: 0.018231706761228456\n",
            "Epoch: 9800, Acc: 0.967, Loss: 0.082, F1: 0.967, Precision: 0.967, Recall: 0.967, LR: 0.018215102141185255\n",
            "Epoch: 9900, Acc: 0.963, Loss: 0.081, F1: 0.963, Precision: 0.963, Recall: 0.963, LR: 0.018198527739105907\n",
            "Epoch: 10000, Acc: 0.967, Loss: 0.081, F1: 0.967, Precision: 0.967, Recall: 0.967, LR: 0.018181983472577025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import nnfs\n",
        "from nnfs.datasets import spiral_data\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "\n",
        "nnfs.init()\n",
        "\n",
        "class Layer_Dense:\n",
        "    def __init__(self, n_inputs, n_neurons):\n",
        "        self.weights = 0.01 * np.random.randn(n_inputs, n_neurons)\n",
        "        self.biases = np.zeros((1, n_neurons))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        self.inputs = inputs\n",
        "        self.output = np.dot(inputs, self.weights) + self.biases\n",
        "\n",
        "    def backward(self, dvalues):\n",
        "        self.dweights = np.dot(self.inputs.T, dvalues)\n",
        "        self.dbiases = np.sum(dvalues, axis=0, keepdims=True)\n",
        "        self.dinputs = np.dot(dvalues, self.weights.T)\n",
        "\n",
        "class Activation_Softmax_Loss_CategoricalCrossentropy:\n",
        "    def __init__(self):\n",
        "        self.activation = Activation_Softmax()\n",
        "        self.loss = Loss_CategoricalCrossentropy()\n",
        "\n",
        "    def forward(self, inputs, y_true):\n",
        "        self.activation.forward(inputs)\n",
        "        self.output = self.activation.output\n",
        "        return self.loss.calculate(self.output, y_true)\n",
        "\n",
        "    def backward(self, dvalues, y_true):\n",
        "        samples = len(dvalues)\n",
        "        if len(y_true.shape) == 2:\n",
        "            y_true = np.argmax(y_true, axis=1)\n",
        "        self.dinputs = dvalues.copy()\n",
        "        self.dinputs[range(samples), y_true] -= 1\n",
        "        self.dinputs = self.dinputs / samples\n",
        "\n",
        "class Activation_Softmax:\n",
        "    def forward(self, inputs):\n",
        "        exp_values = np.exp(inputs - np.max(inputs, axis=1, keepdims=True))\n",
        "        self.output = exp_values / np.sum(exp_values, axis=1, keepdims=True)\n",
        "\n",
        "class Loss_CategoricalCrossentropy:\n",
        "    def forward(self, y_pred, y_true):\n",
        "        samples = len(y_pred)\n",
        "        y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
        "        correct_confidences = y_pred_clipped[range(samples), y_true]\n",
        "        return -np.log(correct_confidences)\n",
        "\n",
        "    def calculate(self, output, y):\n",
        "        return np.mean(self.forward(output, y))\n",
        "\n",
        "class Optimizer_Adam:\n",
        "    def __init__(self, learning_rate=0.001, decay=0., epsilon=1e-7, beta_1=0.9, beta_2=0.999):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.current_learning_rate = learning_rate\n",
        "        self.decay = decay\n",
        "        self.iterations = 0\n",
        "        self.epsilon = epsilon\n",
        "        self.beta_1 = beta_1\n",
        "        self.beta_2 = beta_2\n",
        "\n",
        "    def pre_update_params(self):\n",
        "        if self.decay:\n",
        "            self.current_learning_rate = self.learning_rate * (1. / (1. + self.decay * self.iterations))\n",
        "\n",
        "    def update_params(self, layer):\n",
        "        if not hasattr(layer, 'weight_cache'):\n",
        "            layer.weight_momentums = np.zeros_like(layer.weights)\n",
        "            layer.weight_cache = np.zeros_like(layer.weights)\n",
        "            layer.bias_momentums = np.zeros_like(layer.biases)\n",
        "            layer.bias_cache = np.zeros_like(layer.biases)\n",
        "\n",
        "        layer.weight_momentums = self.beta_1 * layer.weight_momentums + (1 - self.beta_1) * layer.dweights\n",
        "        layer.bias_momentums = self.beta_1 * layer.bias_momentums + (1 - self.beta_1) * layer.dbiases\n",
        "\n",
        "        weight_momentums_corrected = layer.weight_momentums / (1 - self.beta_1 ** (self.iterations + 1))\n",
        "        bias_momentums_corrected = layer.bias_momentums / (1 - self.beta_1 ** (self.iterations + 1))\n",
        "\n",
        "        layer.weight_cache = self.beta_2 * layer.weight_cache + (1 - self.beta_2) * layer.dweights**2\n",
        "        layer.bias_cache = self.beta_2 * layer.bias_cache + (1 - self.beta_2) * layer.dbiases**2\n",
        "\n",
        "        weight_cache_corrected = layer.weight_cache / (1 - self.beta_2 ** (self.iterations + 1))\n",
        "        bias_cache_corrected = layer.bias_cache / (1 - self.beta_2 ** (self.iterations + 1))\n",
        "\n",
        "        layer.weights += -self.current_learning_rate * weight_momentums_corrected / (np.sqrt(weight_cache_corrected) + self.epsilon)\n",
        "        layer.biases += -self.current_learning_rate * bias_momentums_corrected / (np.sqrt(bias_cache_corrected) + self.epsilon)\n",
        "\n",
        "    def post_update_params(self):\n",
        "        self.iterations += 1\n",
        "\n",
        "X, y = spiral_data(samples=100, classes=3)\n",
        "\n",
        "dense = Layer_Dense(2, 3)\n",
        "loss_activation = Activation_Softmax_Loss_CategoricalCrossentropy()\n",
        "optimizer = Optimizer_Adam(learning_rate=0.02, decay=1e-5)\n",
        "\n",
        "for epoch in range(10001):\n",
        "    dense.forward(X)\n",
        "    loss = loss_activation.forward(dense.output, y)\n",
        "    predictions = np.argmax(loss_activation.output, axis=1)\n",
        "    acc = accuracy_score(y, predictions)\n",
        "    f1 = f1_score(y, predictions, average='weighted')\n",
        "    precision = precision_score(y, predictions, average='weighted', zero_division=1)\n",
        "    recall = recall_score(y, predictions, average='weighted', zero_division=1)\n",
        "\n",
        "    if not epoch % 100:\n",
        "        print(f'Epoch: {epoch}, Acc: {acc:.3f}, Loss: {loss:.3f}, F1: {f1:.3f}, Precision: {precision:.3f}, Recall: {recall:.3f}, LR: {optimizer.current_learning_rate}')\n",
        "\n",
        "    loss_activation.backward(loss_activation.output, y)\n",
        "    dense.backward(loss_activation.dinputs)\n",
        "    optimizer.pre_update_params()\n",
        "    optimizer.update_params(dense)\n",
        "    optimizer.post_update_params()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcT7umvtVi38",
        "outputId": "18a57dd4-161c-4093-fc99-6c7bdc5b4ce2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Acc: 0.337, Loss: 1.098, F1: 0.306, Precision: 0.369, Recall: 0.337, LR: 0.02\n",
            "Epoch: 100, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.01998021958261321\n",
            "Epoch: 200, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.019960279044701046\n",
            "Epoch: 300, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.019940378268975763\n",
            "Epoch: 400, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.01992051713662487\n",
            "Epoch: 500, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.01990069552930875\n",
            "Epoch: 600, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.019880913329158343\n",
            "Epoch: 700, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.019861170418772778\n",
            "Epoch: 800, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.019841466681217078\n",
            "Epoch: 900, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.01982180200001982\n",
            "Epoch: 1000, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.019802176259170884\n",
            "Epoch: 1100, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.01978258934311912\n",
            "Epoch: 1200, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.01976304113677013\n",
            "Epoch: 1300, Acc: 0.397, Loss: 1.083, F1: 0.392, Precision: 0.395, Recall: 0.397, LR: 0.019743531525483964\n",
            "Epoch: 1400, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.01972406039507293\n",
            "Epoch: 1500, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.019704627631799327\n",
            "Epoch: 1600, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.019685233122373254\n",
            "Epoch: 1700, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.019665876753950384\n",
            "Epoch: 1800, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.01964655841412981\n",
            "Epoch: 1900, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.019627277990951823\n",
            "Epoch: 2000, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.019608035372895814\n",
            "Epoch: 2100, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.01958883044887805\n",
            "Epoch: 2200, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.019569663108249594\n",
            "Epoch: 2300, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.01955053324079414\n",
            "Epoch: 2400, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.019531440736725945\n",
            "Epoch: 2500, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.019512385486687673\n",
            "Epoch: 2600, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.019493367381748363\n",
            "Epoch: 2700, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.019474386313401298\n",
            "Epoch: 2800, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.019455442173562\n",
            "Epoch: 2900, Acc: 0.393, Loss: 1.083, F1: 0.389, Precision: 0.392, Recall: 0.393, LR: 0.019436534854566128\n",
            "Epoch: 3000, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.01941766424916747\n",
            "Epoch: 3100, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.019398830250535893\n",
            "Epoch: 3200, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.019380032752255354\n",
            "Epoch: 3300, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.01936127164832186\n",
            "Epoch: 3400, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.01934254683314152\n",
            "Epoch: 3500, Acc: 0.387, Loss: 1.083, F1: 0.382, Precision: 0.384, Recall: 0.387, LR: 0.019323858201528515\n",
            "Epoch: 3600, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.019305205648703173\n",
            "Epoch: 3700, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.01928658907028997\n",
            "Epoch: 3800, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.01926800836231563\n",
            "Epoch: 3900, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.019249463421207133\n",
            "Epoch: 4000, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.019230954143789846\n",
            "Epoch: 4100, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.019212480427285565\n",
            "Epoch: 4200, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.019194042169310647\n",
            "Epoch: 4300, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.019175639267874092\n",
            "Epoch: 4400, Acc: 0.390, Loss: 1.083, F1: 0.385, Precision: 0.388, Recall: 0.390, LR: 0.019157271621375684\n",
            "Epoch: 4500, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.0191389391286041\n",
            "Epoch: 4600, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.019120641688735073\n",
            "Epoch: 4700, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.019102379201329525\n",
            "Epoch: 4800, Acc: 0.393, Loss: 1.083, F1: 0.389, Precision: 0.392, Recall: 0.393, LR: 0.01908415156633174\n",
            "Epoch: 4900, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.01906595868406753\n",
            "Epoch: 5000, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.01904780045524243\n",
            "Epoch: 5100, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.019029676780939874\n",
            "Epoch: 5200, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.019011587562619416\n",
            "Epoch: 5300, Acc: 0.393, Loss: 1.083, F1: 0.389, Precision: 0.392, Recall: 0.393, LR: 0.01899353270211493\n",
            "Epoch: 5400, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.018975512101632844\n",
            "Epoch: 5500, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.018957525663750367\n",
            "Epoch: 5600, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.018939573291413745\n",
            "Epoch: 5700, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.018921654887936498\n",
            "Epoch: 5800, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.018903770356997706\n",
            "Epoch: 5900, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.018885919602640248\n",
            "Epoch: 6000, Acc: 0.393, Loss: 1.083, F1: 0.389, Precision: 0.392, Recall: 0.393, LR: 0.018868102529269144\n",
            "Epoch: 6100, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.018850319041649778\n",
            "Epoch: 6200, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.018832569044906263\n",
            "Epoch: 6300, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.018814852444519702\n",
            "Epoch: 6400, Acc: 0.390, Loss: 1.083, F1: 0.385, Precision: 0.388, Recall: 0.390, LR: 0.018797169146326564\n",
            "Epoch: 6500, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.01877951905651696\n",
            "Epoch: 6600, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.018761902081633034\n",
            "Epoch: 6700, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.018744318128567278\n",
            "Epoch: 6800, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.018726767104560903\n",
            "Epoch: 6900, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.018709248917202218\n",
            "Epoch: 7000, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.018691763474424996\n",
            "Epoch: 7100, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.018674310684506857\n",
            "Epoch: 7200, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.01865689045606769\n",
            "Epoch: 7300, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.01863950269806802\n",
            "Epoch: 7400, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.018622147319807447\n",
            "Epoch: 7500, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.018604824230923075\n",
            "Epoch: 7600, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.01858753334138793\n",
            "Epoch: 7700, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.018570274561509396\n",
            "Epoch: 7800, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.018553047801927663\n",
            "Epoch: 7900, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.018535852973614212\n",
            "Epoch: 8000, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.01851868998787026\n",
            "Epoch: 8100, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.018501558756325222\n",
            "Epoch: 8200, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.01848445919093522\n",
            "Epoch: 8300, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.018467391203981567\n",
            "Epoch: 8400, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.018450354708069265\n",
            "Epoch: 8500, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.018433349616125496\n",
            "Epoch: 8600, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.018416375841398172\n",
            "Epoch: 8700, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.01839943329745444\n",
            "Epoch: 8800, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.01838252189817921\n",
            "Epoch: 8900, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.018365641557773718\n",
            "Epoch: 9000, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.018348792190754044\n",
            "Epoch: 9100, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.0183319737119497\n",
            "Epoch: 9200, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.018315186036502167\n",
            "Epoch: 9300, Acc: 0.397, Loss: 1.083, F1: 0.391, Precision: 0.395, Recall: 0.397, LR: 0.018298429079863496\n",
            "Epoch: 9400, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.018281702757794862\n",
            "Epoch: 9500, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.018265006986365174\n",
            "Epoch: 9600, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.018248341681949654\n",
            "Epoch: 9700, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.018231706761228456\n",
            "Epoch: 9800, Acc: 0.393, Loss: 1.083, F1: 0.388, Precision: 0.391, Recall: 0.393, LR: 0.018215102141185255\n",
            "Epoch: 9900, Acc: 0.393, Loss: 1.083, F1: 0.389, Precision: 0.392, Recall: 0.393, LR: 0.018198527739105907\n",
            "Epoch: 10000, Acc: 0.393, Loss: 1.083, F1: 0.389, Precision: 0.392, Recall: 0.393, LR: 0.018181983472577025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import nnfs\n",
        "from nnfs.datasets import spiral_data\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "\n",
        "nnfs.init()\n",
        "\n",
        "# Dense Layer with Batch Normalization and L2 Regularization\n",
        "class Layer_Dense:\n",
        "    def __init__(self, n_inputs, n_neurons, l2_reg=0.01):\n",
        "        self.weights = 0.01 * np.random.randn(n_inputs, n_neurons)\n",
        "        self.biases = np.zeros((1, n_neurons))\n",
        "        self.l2_reg = l2_reg  # L2 Regularization factor\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        self.inputs = inputs\n",
        "        self.output = np.dot(inputs, self.weights) + self.biases\n",
        "\n",
        "        # Apply Batch Normalization\n",
        "        self.mean = np.mean(self.output, axis=0, keepdims=True)\n",
        "        self.std = np.std(self.output, axis=0, keepdims=True) + 1e-7\n",
        "        self.output = (self.output - self.mean) / self.std\n",
        "\n",
        "    def backward(self, dvalues):\n",
        "        self.dweights = np.dot(self.inputs.T, dvalues) + self.l2_reg * self.weights\n",
        "        self.dbiases = np.sum(dvalues, axis=0, keepdims=True)\n",
        "        self.dinputs = np.dot(dvalues, self.weights.T)\n",
        "\n",
        "# Leaky ReLU Activation\n",
        "class Activation_LeakyReLU:\n",
        "    def __init__(self, alpha=0.01):\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        self.inputs = inputs\n",
        "        self.output = np.where(inputs > 0, inputs, self.alpha * inputs)\n",
        "\n",
        "    def backward(self, dvalues):\n",
        "        self.dinputs = dvalues.copy()\n",
        "        self.dinputs[self.inputs <= 0] *= self.alpha\n",
        "\n",
        "# Softmax Activation\n",
        "class Activation_Softmax:\n",
        "    def forward(self, inputs):\n",
        "        exp_values = np.exp(inputs - np.max(inputs, axis=1, keepdims=True))\n",
        "        self.output = exp_values / np.sum(exp_values, axis=1, keepdims=True)\n",
        "\n",
        "# Categorical Cross-Entropy Loss\n",
        "class Loss_CategoricalCrossentropy:\n",
        "    def forward(self, y_pred, y_true):\n",
        "        samples = len(y_pred)\n",
        "        y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
        "\n",
        "        if len(y_true.shape) == 1:\n",
        "            correct_confidences = y_pred_clipped[range(samples), y_true]\n",
        "        elif len(y_true.shape) == 2:\n",
        "            correct_confidences = np.sum(y_pred_clipped * y_true, axis=1)\n",
        "\n",
        "        negative_log_likelihoods = -np.log(correct_confidences)\n",
        "        return np.mean(negative_log_likelihoods)\n",
        "\n",
        "    def backward(self, dvalues, y_true):\n",
        "        samples = len(dvalues)\n",
        "        labels = len(dvalues[0])\n",
        "\n",
        "        if len(y_true.shape) == 1:\n",
        "            y_true = np.eye(labels)[y_true]\n",
        "\n",
        "        self.dinputs = -y_true / dvalues\n",
        "        self.dinputs = self.dinputs / samples\n",
        "\n",
        "# Combined Softmax & Loss for efficiency\n",
        "class Activation_Softmax_Loss_CategoricalCrossentropy:\n",
        "    def __init__(self):\n",
        "        self.activation = Activation_Softmax()\n",
        "        self.loss = Loss_CategoricalCrossentropy()\n",
        "\n",
        "    def forward(self, inputs, y_true):\n",
        "        self.activation.forward(inputs)\n",
        "        self.output = self.activation.output\n",
        "        return self.loss.forward(self.output, y_true)\n",
        "\n",
        "    def backward(self, dvalues, y_true):\n",
        "        samples = len(dvalues)\n",
        "        if len(y_true.shape) == 2:\n",
        "            y_true = np.argmax(y_true, axis=1)\n",
        "        self.dinputs = dvalues.copy()\n",
        "        self.dinputs[range(samples), y_true] -= 1\n",
        "        self.dinputs = self.dinputs / samples\n",
        "\n",
        "# Adam Optimizer with Dynamic Learning Rate\n",
        "class Optimizer_Adam:\n",
        "    def __init__(self, learning_rate=0.005, decay=1e-6, epsilon=1e-7, beta_1=0.9, beta_2=0.999):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.current_learning_rate = learning_rate\n",
        "        self.decay = decay\n",
        "        self.iterations = 0\n",
        "        self.epsilon = epsilon\n",
        "        self.beta_1 = beta_1\n",
        "        self.beta_2 = beta_2\n",
        "\n",
        "    def pre_update_params(self):\n",
        "        if self.decay:\n",
        "            self.current_learning_rate = self.learning_rate * (1. / (1. + self.decay * self.iterations))\n",
        "\n",
        "    def update_params(self, layer):\n",
        "        if not hasattr(layer, 'weight_cache'):\n",
        "            layer.weight_momentums = np.zeros_like(layer.weights)\n",
        "            layer.weight_cache = np.zeros_like(layer.weights)\n",
        "            layer.bias_momentums = np.zeros_like(layer.biases)\n",
        "            layer.bias_cache = np.zeros_like(layer.biases)\n",
        "\n",
        "        layer.weight_momentums = self.beta_1 * layer.weight_momentums + (1 - self.beta_1) * layer.dweights\n",
        "        layer.bias_momentums = self.beta_1 * layer.bias_momentums + (1 - self.beta_1) * layer.dbiases\n",
        "\n",
        "        weight_momentums_corrected = layer.weight_momentums / (1 - self.beta_1 ** (self.iterations + 1))\n",
        "        bias_momentums_corrected = layer.bias_momentums / (1 - self.beta_1 ** (self.iterations + 1))\n",
        "\n",
        "        layer.weight_cache = self.beta_2 * layer.weight_cache + (1 - self.beta_2) * layer.dweights**2\n",
        "        layer.bias_cache = self.beta_2 * layer.bias_cache + (1 - self.beta_2) * layer.dbiases**2\n",
        "\n",
        "        weight_cache_corrected = layer.weight_cache / (1 - self.beta_2 ** (self.iterations + 1))\n",
        "        bias_cache_corrected = layer.bias_cache / (1 - self.beta_2 ** (self.iterations + 1))\n",
        "\n",
        "        layer.weights += -self.current_learning_rate * weight_momentums_corrected / (np.sqrt(weight_cache_corrected) + self.epsilon)\n",
        "        layer.biases += -self.current_learning_rate * bias_momentums_corrected / (np.sqrt(bias_cache_corrected) + self.epsilon)\n",
        "\n",
        "    def post_update_params(self):\n",
        "        self.iterations += 1\n",
        "\n",
        "# Generate dataset\n",
        "X, y = spiral_data(samples=100, classes=3)\n",
        "\n",
        "# Create layers\n",
        "dense1 = Layer_Dense(2, 128)  # Increased to 128 neurons\n",
        "activation1 = Activation_LeakyReLU()\n",
        "loss_activation = Activation_Softmax_Loss_CategoricalCrossentropy()\n",
        "optimizer = Optimizer_Adam(learning_rate=0.005, decay=1e-6)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(20001):  # Increased training epochs\n",
        "    dense1.forward(X)\n",
        "    activation1.forward(dense1.output)\n",
        "    loss = loss_activation.forward(activation1.output, y)\n",
        "\n",
        "    predictions = np.argmax(loss_activation.output, axis=1)\n",
        "\n",
        "    acc = accuracy_score(y, predictions)\n",
        "    f1 = f1_score(y, predictions, average='weighted')\n",
        "    precision = precision_score(y, predictions, average='weighted', zero_division=1)\n",
        "    recall = recall_score(y, predictions, average='weighted', zero_division=1)\n",
        "\n",
        "    if not epoch % 100:\n",
        "        print(f'Epoch: {epoch}, Acc: {acc:.3f}, Loss: {loss:.3f}, F1: {f1:.3f}, Precision: {precision:.3f}, Recall: {recall:.3f}, LR: {optimizer.current_learning_rate:.6f}')\n",
        "\n",
        "    loss_activation.backward(loss_activation.output, y)\n",
        "    activation1.backward(loss_activation.dinputs)\n",
        "    dense1.backward(activation1.dinputs)\n",
        "\n",
        "    optimizer.pre_update_params()\n",
        "    optimizer.update_params(dense1)\n",
        "    optimizer.post_update_params()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvsLMaF9WtJ0",
        "outputId": "8f34daea-8980-406c-f301-638401e3157c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Acc: 0.000, Loss: 5.001, F1: 0.000, Precision: 0.667, Recall: 0.000, LR: 0.005000\n",
            "Epoch: 100, Acc: 0.013, Loss: 4.961, F1: 0.025, Precision: 0.474, Recall: 0.013, LR: 0.005000\n",
            "Epoch: 200, Acc: 0.013, Loss: 4.967, F1: 0.026, Precision: 0.444, Recall: 0.013, LR: 0.004999\n",
            "Epoch: 300, Acc: 0.020, Loss: 4.963, F1: 0.035, Precision: 0.511, Recall: 0.020, LR: 0.004999\n",
            "Epoch: 400, Acc: 0.023, Loss: 4.952, F1: 0.044, Precision: 0.333, Recall: 0.023, LR: 0.004998\n",
            "Epoch: 500, Acc: 0.000, Loss: 4.955, F1: 0.000, Precision: 0.333, Recall: 0.000, LR: 0.004998\n",
            "Epoch: 600, Acc: 0.013, Loss: 4.954, F1: 0.026, Precision: 0.333, Recall: 0.013, LR: 0.004997\n",
            "Epoch: 700, Acc: 0.003, Loss: 4.953, F1: 0.006, Precision: 0.750, Recall: 0.003, LR: 0.004997\n",
            "Epoch: 800, Acc: 0.017, Loss: 4.944, F1: 0.032, Precision: 0.333, Recall: 0.017, LR: 0.004996\n",
            "Epoch: 900, Acc: 0.007, Loss: 4.946, F1: 0.013, Precision: 0.889, Recall: 0.007, LR: 0.004996\n",
            "Epoch: 1000, Acc: 0.003, Loss: 4.942, F1: 0.006, Precision: 0.778, Recall: 0.003, LR: 0.004995\n",
            "Epoch: 1100, Acc: 0.000, Loss: 4.942, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004995\n",
            "Epoch: 1200, Acc: 0.003, Loss: 4.936, F1: 0.007, Precision: 1.000, Recall: 0.003, LR: 0.004994\n",
            "Epoch: 1300, Acc: 0.007, Loss: 4.940, F1: 0.013, Precision: 0.889, Recall: 0.007, LR: 0.004994\n",
            "Epoch: 1400, Acc: 0.007, Loss: 4.939, F1: 0.013, Precision: 0.778, Recall: 0.007, LR: 0.004993\n",
            "Epoch: 1500, Acc: 0.000, Loss: 4.930, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004993\n",
            "Epoch: 1600, Acc: 0.000, Loss: 4.933, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004992\n",
            "Epoch: 1700, Acc: 0.000, Loss: 4.932, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004992\n",
            "Epoch: 1800, Acc: 0.003, Loss: 4.929, F1: 0.007, Precision: 1.000, Recall: 0.003, LR: 0.004991\n",
            "Epoch: 1900, Acc: 0.013, Loss: 4.920, F1: 0.025, Precision: 0.933, Recall: 0.013, LR: 0.004991\n",
            "Epoch: 2000, Acc: 0.000, Loss: 4.928, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004990\n",
            "Epoch: 2100, Acc: 0.000, Loss: 4.918, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004990\n",
            "Epoch: 2200, Acc: 0.007, Loss: 4.918, F1: 0.013, Precision: 0.833, Recall: 0.007, LR: 0.004989\n",
            "Epoch: 2300, Acc: 0.003, Loss: 4.925, F1: 0.007, Precision: 1.000, Recall: 0.003, LR: 0.004989\n",
            "Epoch: 2400, Acc: 0.007, Loss: 4.920, F1: 0.013, Precision: 0.833, Recall: 0.007, LR: 0.004988\n",
            "Epoch: 2500, Acc: 0.000, Loss: 4.914, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004988\n",
            "Epoch: 2600, Acc: 0.010, Loss: 4.927, F1: 0.019, Precision: 0.667, Recall: 0.010, LR: 0.004987\n",
            "Epoch: 2700, Acc: 0.000, Loss: 4.922, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004987\n",
            "Epoch: 2800, Acc: 0.000, Loss: 4.925, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004986\n",
            "Epoch: 2900, Acc: 0.007, Loss: 4.910, F1: 0.013, Precision: 0.800, Recall: 0.007, LR: 0.004986\n",
            "Epoch: 3000, Acc: 0.007, Loss: 4.921, F1: 0.013, Precision: 1.000, Recall: 0.007, LR: 0.004985\n",
            "Epoch: 3100, Acc: 0.000, Loss: 4.929, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004985\n",
            "Epoch: 3200, Acc: 0.010, Loss: 4.922, F1: 0.020, Precision: 0.833, Recall: 0.010, LR: 0.004984\n",
            "Epoch: 3300, Acc: 0.003, Loss: 4.916, F1: 0.006, Precision: 0.778, Recall: 0.003, LR: 0.004984\n",
            "Epoch: 3400, Acc: 0.000, Loss: 4.923, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004983\n",
            "Epoch: 3500, Acc: 0.003, Loss: 4.924, F1: 0.007, Precision: 1.000, Recall: 0.003, LR: 0.004983\n",
            "Epoch: 3600, Acc: 0.007, Loss: 4.899, F1: 0.013, Precision: 1.000, Recall: 0.007, LR: 0.004982\n",
            "Epoch: 3700, Acc: 0.000, Loss: 4.913, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004982\n",
            "Epoch: 3800, Acc: 0.013, Loss: 4.916, F1: 0.026, Precision: 1.000, Recall: 0.013, LR: 0.004981\n",
            "Epoch: 3900, Acc: 0.000, Loss: 4.908, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004981\n",
            "Epoch: 4000, Acc: 0.003, Loss: 4.908, F1: 0.007, Precision: 1.000, Recall: 0.003, LR: 0.004980\n",
            "Epoch: 4100, Acc: 0.000, Loss: 4.916, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004980\n",
            "Epoch: 4200, Acc: 0.000, Loss: 4.926, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004979\n",
            "Epoch: 4300, Acc: 0.003, Loss: 4.926, F1: 0.007, Precision: 1.000, Recall: 0.003, LR: 0.004979\n",
            "Epoch: 4400, Acc: 0.000, Loss: 4.926, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004978\n",
            "Epoch: 4500, Acc: 0.000, Loss: 4.940, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004978\n",
            "Epoch: 4600, Acc: 0.003, Loss: 4.904, F1: 0.007, Precision: 1.000, Recall: 0.003, LR: 0.004977\n",
            "Epoch: 4700, Acc: 0.000, Loss: 4.922, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004977\n",
            "Epoch: 4800, Acc: 0.000, Loss: 4.934, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004976\n",
            "Epoch: 4900, Acc: 0.000, Loss: 4.935, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004976\n",
            "Epoch: 5000, Acc: 0.003, Loss: 4.948, F1: 0.007, Precision: 1.000, Recall: 0.003, LR: 0.004975\n",
            "Epoch: 5100, Acc: 0.000, Loss: 4.917, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004975\n",
            "Epoch: 5200, Acc: 0.003, Loss: 4.929, F1: 0.007, Precision: 1.000, Recall: 0.003, LR: 0.004974\n",
            "Epoch: 5300, Acc: 0.000, Loss: 4.916, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004974\n",
            "Epoch: 5400, Acc: 0.003, Loss: 4.907, F1: 0.007, Precision: 1.000, Recall: 0.003, LR: 0.004973\n",
            "Epoch: 5500, Acc: 0.000, Loss: 4.945, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004973\n",
            "Epoch: 5600, Acc: 0.000, Loss: 4.915, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004972\n",
            "Epoch: 5700, Acc: 0.000, Loss: 4.921, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004972\n",
            "Epoch: 5800, Acc: 0.000, Loss: 4.944, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004971\n",
            "Epoch: 5900, Acc: 0.000, Loss: 4.913, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004971\n",
            "Epoch: 6000, Acc: 0.000, Loss: 4.911, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004970\n",
            "Epoch: 6100, Acc: 0.000, Loss: 4.931, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004970\n",
            "Epoch: 6200, Acc: 0.000, Loss: 4.945, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004969\n",
            "Epoch: 6300, Acc: 0.007, Loss: 4.901, F1: 0.013, Precision: 1.000, Recall: 0.007, LR: 0.004969\n",
            "Epoch: 6400, Acc: 0.000, Loss: 4.921, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004968\n",
            "Epoch: 6500, Acc: 0.000, Loss: 4.926, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004968\n",
            "Epoch: 6600, Acc: 0.000, Loss: 4.932, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004967\n",
            "Epoch: 6700, Acc: 0.000, Loss: 4.944, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004967\n",
            "Epoch: 6800, Acc: 0.000, Loss: 4.925, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004966\n",
            "Epoch: 6900, Acc: 0.007, Loss: 4.924, F1: 0.013, Precision: 1.000, Recall: 0.007, LR: 0.004966\n",
            "Epoch: 7000, Acc: 0.000, Loss: 4.928, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004965\n",
            "Epoch: 7100, Acc: 0.000, Loss: 4.922, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004965\n",
            "Epoch: 7200, Acc: 0.010, Loss: 4.935, F1: 0.019, Precision: 0.833, Recall: 0.010, LR: 0.004964\n",
            "Epoch: 7300, Acc: 0.000, Loss: 4.924, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004964\n",
            "Epoch: 7400, Acc: 0.013, Loss: 4.901, F1: 0.025, Precision: 0.857, Recall: 0.013, LR: 0.004963\n",
            "Epoch: 7500, Acc: 0.000, Loss: 4.919, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004963\n",
            "Epoch: 7600, Acc: 0.000, Loss: 4.941, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004962\n",
            "Epoch: 7700, Acc: 0.000, Loss: 4.946, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004962\n",
            "Epoch: 7800, Acc: 0.000, Loss: 4.951, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004961\n",
            "Epoch: 7900, Acc: 0.000, Loss: 4.923, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004961\n",
            "Epoch: 8000, Acc: 0.000, Loss: 4.933, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004960\n",
            "Epoch: 8100, Acc: 0.000, Loss: 4.924, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004960\n",
            "Epoch: 8200, Acc: 0.000, Loss: 4.952, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004959\n",
            "Epoch: 8300, Acc: 0.000, Loss: 4.940, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004959\n",
            "Epoch: 8400, Acc: 0.000, Loss: 4.942, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004958\n",
            "Epoch: 8500, Acc: 0.007, Loss: 4.900, F1: 0.013, Precision: 1.000, Recall: 0.007, LR: 0.004958\n",
            "Epoch: 8600, Acc: 0.000, Loss: 4.954, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004957\n",
            "Epoch: 8700, Acc: 0.000, Loss: 4.949, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004957\n",
            "Epoch: 8800, Acc: 0.000, Loss: 4.939, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004956\n",
            "Epoch: 8900, Acc: 0.000, Loss: 4.922, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004956\n",
            "Epoch: 9000, Acc: 0.000, Loss: 4.889, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004955\n",
            "Epoch: 9100, Acc: 0.000, Loss: 4.924, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004955\n",
            "Epoch: 9200, Acc: 0.000, Loss: 4.966, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004954\n",
            "Epoch: 9300, Acc: 0.000, Loss: 4.969, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004954\n",
            "Epoch: 9400, Acc: 0.000, Loss: 4.940, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004953\n",
            "Epoch: 9500, Acc: 0.000, Loss: 4.946, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004953\n",
            "Epoch: 9600, Acc: 0.000, Loss: 4.926, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004952\n",
            "Epoch: 9700, Acc: 0.000, Loss: 4.950, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004952\n",
            "Epoch: 9800, Acc: 0.000, Loss: 4.939, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004951\n",
            "Epoch: 9900, Acc: 0.000, Loss: 4.913, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004951\n",
            "Epoch: 10000, Acc: 0.000, Loss: 4.897, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004950\n",
            "Epoch: 10100, Acc: 0.000, Loss: 4.934, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004950\n",
            "Epoch: 10200, Acc: 0.007, Loss: 4.925, F1: 0.013, Precision: 1.000, Recall: 0.007, LR: 0.004950\n",
            "Epoch: 10300, Acc: 0.000, Loss: 4.961, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004949\n",
            "Epoch: 10400, Acc: 0.007, Loss: 4.955, F1: 0.013, Precision: 0.833, Recall: 0.007, LR: 0.004949\n",
            "Epoch: 10500, Acc: 0.000, Loss: 4.919, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004948\n",
            "Epoch: 10600, Acc: 0.000, Loss: 4.917, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004948\n",
            "Epoch: 10700, Acc: 0.000, Loss: 4.930, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004947\n",
            "Epoch: 10800, Acc: 0.000, Loss: 4.912, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004947\n",
            "Epoch: 10900, Acc: 0.000, Loss: 4.939, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004946\n",
            "Epoch: 11000, Acc: 0.000, Loss: 4.952, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004946\n",
            "Epoch: 11100, Acc: 0.000, Loss: 4.978, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004945\n",
            "Epoch: 11200, Acc: 0.003, Loss: 4.904, F1: 0.007, Precision: 1.000, Recall: 0.003, LR: 0.004945\n",
            "Epoch: 11300, Acc: 0.000, Loss: 4.968, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004944\n",
            "Epoch: 11400, Acc: 0.000, Loss: 4.943, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004944\n",
            "Epoch: 11500, Acc: 0.000, Loss: 4.959, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004943\n",
            "Epoch: 11600, Acc: 0.017, Loss: 4.929, F1: 0.032, Precision: 0.867, Recall: 0.017, LR: 0.004943\n",
            "Epoch: 11700, Acc: 0.000, Loss: 4.906, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004942\n",
            "Epoch: 11800, Acc: 0.000, Loss: 4.955, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004942\n",
            "Epoch: 11900, Acc: 0.000, Loss: 4.950, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004941\n",
            "Epoch: 12000, Acc: 0.007, Loss: 4.943, F1: 0.013, Precision: 1.000, Recall: 0.007, LR: 0.004941\n",
            "Epoch: 12100, Acc: 0.000, Loss: 4.913, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004940\n",
            "Epoch: 12200, Acc: 0.003, Loss: 4.914, F1: 0.007, Precision: 1.000, Recall: 0.003, LR: 0.004940\n",
            "Epoch: 12300, Acc: 0.000, Loss: 4.953, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004939\n",
            "Epoch: 12400, Acc: 0.000, Loss: 4.932, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004939\n",
            "Epoch: 12500, Acc: 0.000, Loss: 4.950, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004938\n",
            "Epoch: 12600, Acc: 0.000, Loss: 4.948, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004938\n",
            "Epoch: 12700, Acc: 0.000, Loss: 4.900, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004937\n",
            "Epoch: 12800, Acc: 0.000, Loss: 4.911, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004937\n",
            "Epoch: 12900, Acc: 0.000, Loss: 4.916, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004936\n",
            "Epoch: 13000, Acc: 0.000, Loss: 4.931, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004936\n",
            "Epoch: 13100, Acc: 0.000, Loss: 4.913, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004935\n",
            "Epoch: 13200, Acc: 0.000, Loss: 4.946, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004935\n",
            "Epoch: 13300, Acc: 0.000, Loss: 4.908, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004934\n",
            "Epoch: 13400, Acc: 0.000, Loss: 4.936, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004934\n",
            "Epoch: 13500, Acc: 0.003, Loss: 4.921, F1: 0.007, Precision: 1.000, Recall: 0.003, LR: 0.004933\n",
            "Epoch: 13600, Acc: 0.007, Loss: 4.951, F1: 0.013, Precision: 1.000, Recall: 0.007, LR: 0.004933\n",
            "Epoch: 13700, Acc: 0.000, Loss: 4.934, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004932\n",
            "Epoch: 13800, Acc: 0.000, Loss: 4.893, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004932\n",
            "Epoch: 13900, Acc: 0.000, Loss: 4.916, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004931\n",
            "Epoch: 14000, Acc: 0.000, Loss: 4.937, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004931\n",
            "Epoch: 14100, Acc: 0.000, Loss: 4.953, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004930\n",
            "Epoch: 14200, Acc: 0.000, Loss: 4.893, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004930\n",
            "Epoch: 14300, Acc: 0.000, Loss: 4.940, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004930\n",
            "Epoch: 14400, Acc: 0.000, Loss: 4.917, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004929\n",
            "Epoch: 14500, Acc: 0.000, Loss: 4.924, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004929\n",
            "Epoch: 14600, Acc: 0.000, Loss: 4.943, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004928\n",
            "Epoch: 14700, Acc: 0.000, Loss: 4.910, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004928\n",
            "Epoch: 14800, Acc: 0.000, Loss: 4.932, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004927\n",
            "Epoch: 14900, Acc: 0.000, Loss: 4.917, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004927\n",
            "Epoch: 15000, Acc: 0.003, Loss: 4.901, F1: 0.007, Precision: 1.000, Recall: 0.003, LR: 0.004926\n",
            "Epoch: 15100, Acc: 0.000, Loss: 4.915, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004926\n",
            "Epoch: 15200, Acc: 0.023, Loss: 4.922, F1: 0.041, Precision: 0.846, Recall: 0.023, LR: 0.004925\n",
            "Epoch: 15300, Acc: 0.000, Loss: 4.949, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004925\n",
            "Epoch: 15400, Acc: 0.000, Loss: 4.899, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004924\n",
            "Epoch: 15500, Acc: 0.000, Loss: 4.918, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004924\n",
            "Epoch: 15600, Acc: 0.000, Loss: 4.901, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004923\n",
            "Epoch: 15700, Acc: 0.000, Loss: 4.927, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004923\n",
            "Epoch: 15800, Acc: 0.000, Loss: 4.926, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004922\n",
            "Epoch: 15900, Acc: 0.000, Loss: 4.925, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004922\n",
            "Epoch: 16000, Acc: 0.000, Loss: 4.914, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004921\n",
            "Epoch: 16100, Acc: 0.010, Loss: 4.924, F1: 0.019, Precision: 0.917, Recall: 0.010, LR: 0.004921\n",
            "Epoch: 16200, Acc: 0.000, Loss: 4.924, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004920\n",
            "Epoch: 16300, Acc: 0.000, Loss: 4.890, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004920\n",
            "Epoch: 16400, Acc: 0.000, Loss: 4.890, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004919\n",
            "Epoch: 16500, Acc: 0.000, Loss: 4.908, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004919\n",
            "Epoch: 16600, Acc: 0.000, Loss: 4.898, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004918\n",
            "Epoch: 16700, Acc: 0.007, Loss: 4.894, F1: 0.013, Precision: 0.800, Recall: 0.007, LR: 0.004918\n",
            "Epoch: 16800, Acc: 0.000, Loss: 4.925, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004917\n",
            "Epoch: 16900, Acc: 0.000, Loss: 4.884, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004917\n",
            "Epoch: 17000, Acc: 0.000, Loss: 4.906, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004916\n",
            "Epoch: 17100, Acc: 0.007, Loss: 4.929, F1: 0.013, Precision: 1.000, Recall: 0.007, LR: 0.004916\n",
            "Epoch: 17200, Acc: 0.000, Loss: 4.980, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004915\n",
            "Epoch: 17300, Acc: 0.003, Loss: 4.928, F1: 0.007, Precision: 1.000, Recall: 0.003, LR: 0.004915\n",
            "Epoch: 17400, Acc: 0.000, Loss: 4.947, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004914\n",
            "Epoch: 17500, Acc: 0.000, Loss: 4.933, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004914\n",
            "Epoch: 17600, Acc: 0.000, Loss: 4.926, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004914\n",
            "Epoch: 17700, Acc: 0.000, Loss: 4.875, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004913\n",
            "Epoch: 17800, Acc: 0.000, Loss: 4.940, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004913\n",
            "Epoch: 17900, Acc: 0.000, Loss: 4.875, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004912\n",
            "Epoch: 18000, Acc: 0.000, Loss: 4.876, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004912\n",
            "Epoch: 18100, Acc: 0.000, Loss: 4.889, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004911\n",
            "Epoch: 18200, Acc: 0.003, Loss: 4.915, F1: 0.007, Precision: 1.000, Recall: 0.003, LR: 0.004911\n",
            "Epoch: 18300, Acc: 0.000, Loss: 4.886, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004910\n",
            "Epoch: 18400, Acc: 0.000, Loss: 4.929, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004910\n",
            "Epoch: 18500, Acc: 0.007, Loss: 4.860, F1: 0.013, Precision: 1.000, Recall: 0.007, LR: 0.004909\n",
            "Epoch: 18600, Acc: 0.007, Loss: 4.907, F1: 0.013, Precision: 0.889, Recall: 0.007, LR: 0.004909\n",
            "Epoch: 18700, Acc: 0.000, Loss: 4.878, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004908\n",
            "Epoch: 18800, Acc: 0.000, Loss: 4.965, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004908\n",
            "Epoch: 18900, Acc: 0.000, Loss: 4.897, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004907\n",
            "Epoch: 19000, Acc: 0.000, Loss: 4.909, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004907\n",
            "Epoch: 19100, Acc: 0.000, Loss: 4.922, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004906\n",
            "Epoch: 19200, Acc: 0.000, Loss: 4.873, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004906\n",
            "Epoch: 19300, Acc: 0.000, Loss: 4.928, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004905\n",
            "Epoch: 19400, Acc: 0.000, Loss: 4.971, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004905\n",
            "Epoch: 19500, Acc: 0.000, Loss: 4.880, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004904\n",
            "Epoch: 19600, Acc: 0.000, Loss: 4.897, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004904\n",
            "Epoch: 19700, Acc: 0.000, Loss: 4.912, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004903\n",
            "Epoch: 19800, Acc: 0.003, Loss: 4.900, F1: 0.007, Precision: 1.000, Recall: 0.003, LR: 0.004903\n",
            "Epoch: 19900, Acc: 0.000, Loss: 4.953, F1: 0.000, Precision: 1.000, Recall: 0.000, LR: 0.004902\n",
            "Epoch: 20000, Acc: 0.007, Loss: 4.858, F1: 0.013, Precision: 0.833, Recall: 0.007, LR: 0.004902\n"
          ]
        }
      ]
    }
  ]
}